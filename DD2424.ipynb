{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187cbf1d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "25a68103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time\n",
    "import copy\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdbadc",
   "metadata": {},
   "source": [
    "## Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "55608c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_classes = 37 #Number of classes in dataset\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 224\n",
    "batch_size = 128\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e40f1",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0571b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    params_to_update = list(model.named_parameters())\n",
    "    \n",
    "    if feature_extracting:\n",
    "        for name, param in params_to_update:\n",
    "            param.requires_grad = False      \n",
    "    else:\n",
    "        for module, param in zip(model.modules(), model.parameters()):\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extracting): #Initialize Resnet\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True) \n",
    "        \n",
    "        set_parameter_requires_grad(model, feature_extracting)\n",
    "        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        head = nn.Sequential(nn.BatchNorm1d(num_ftrs),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(0.25),\n",
    "                nn.Linear(num_ftrs, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, num_classes))\n",
    "        \n",
    "        #model.fc = nn.Linear(num_ftrs,num_classes) # Update last layer to binary classification (Dog/cat)\n",
    "        model.fc = head#nn.Linear(num_ftrs,num_classes) # Update last layer to binary classification (Dog/cat)\n",
    "        input_size = 224 #\"Finally, notice that inception_v3 requires the input size to be (299,299), whereas all of the other models expect (224,224).\"\n",
    "        model = model.to(device)\n",
    "        \n",
    "    return model, input_size\n",
    "\n",
    "\n",
    "\n",
    "def readData(target_type):# = 'breeds'):\n",
    "    breed_to_species = {0:0, 1:1, 2:1, 3:1, 4:1, 5:0, 6:0, 7:0, 8:1, 9:0, 10:1,\n",
    "                    11:0, 12:1, 13:1, 14:1, 15:1, 16:1, 17:1, 18:1, 19:1, 20:0,\n",
    "                    21:1, 22:1, 23:0, 24:1, 25:1, 26:0, 27:0, 28:1, 29:1, 30:1,\n",
    "                    31:1, 32:0, 33:0, 34:1, 35:1, 36:1\n",
    "                   }\n",
    "    \n",
    "    transform_train = T.Compose([\n",
    "                           #T.Resize(256),\n",
    "                            T.Resize(image_size),\n",
    "\n",
    "                           T.CenterCrop(image_size),\n",
    "                           #T.RandomHorizontalFlip(p=0.5),\n",
    "                           ##T.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "                           #T.RandomRotation(degrees=90),\n",
    "                           T.ToTensor(),\n",
    "                           T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                           #T.RandomResizedCrop(size=image_size)\n",
    "                          ])\n",
    "    \n",
    "\n",
    "    \n",
    "    transform_test = T.Compose([T.Resize(image_size),\n",
    "        #T.Resize(256),\n",
    "                            T.CenterCrop(image_size),\n",
    "                           T.ToTensor(),\n",
    "                           T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                          ])\n",
    "    if target_type == 'species':\n",
    "        target_function = (lambda x: breed_to_species.get(x))\n",
    "    elif target_type == 'breeds':\n",
    "        target_function = None\n",
    "    else:\n",
    "        raise Exception(\"Wrong target type\")\n",
    "        \n",
    "    trainval = OxfordIIITPet(path,\n",
    "                             target_types= \"category\",\n",
    "                             transform=transform_train,\n",
    "                             split = 'trainval',\n",
    "                             target_transform = target_function\n",
    "                            )\n",
    "    test = OxfordIIITPet(path,\n",
    "                         target_types= \"category\",\n",
    "                         transform=transform_test,\n",
    "                         split = 'test',\n",
    "                         target_transform = target_function\n",
    "                        )\n",
    "                         \n",
    "    #train, val = splitData(trainval, 0.95, 0.05)\n",
    "    return trainval, test #train, val, test\n",
    "    \n",
    "def splitData(dataset,nrTrain,nrVal):\n",
    "    len1 = int(nrTrain*len(dataset))\n",
    "    len2 = int(len(dataset) - len1)\n",
    "    train, val = torch.utils.data.random_split(dataset, [len1,len2])\n",
    "    return train, val\n",
    "\n",
    "def show_example(img, label):\n",
    "    print('Label: ', train_dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa2c0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler = None, num_epochs=25):\n",
    "    since = time.time()\n",
    "    loss_history = []\n",
    "    val_acc_history = []\n",
    "    acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += float(loss.item() * inputs.size(0))\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            #if phase == 'train' and scheduler == None:\n",
    "                #scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            loss_history.append(epoch_loss)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            acc_history.append(epoch_acc)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history,loss_history,acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c280de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, dataloader, criterion):\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    print('Acc: {:4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6bd68",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c3a19b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val    = readData(\n",
    "                            #target_type = 'species'\n",
    "                            target_type = 'breeds'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a1d8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, _ = splitData(train, 0.20, 0.8)\n",
    "#val, _ = splitData(val, 0.20,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4d634ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\GTSA - Infinity/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model,input_size = initialize_model(model_name = \"resnet\",\n",
    "                                    num_classes = 37,\n",
    "                                    feature_extracting = True)\n",
    "\n",
    "\n",
    "dataloaders = {label: torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "          for label, data in zip(['train', 'val'],[train, val])}\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4e15b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 3.1194 Acc: 0.2313\n",
      "val Loss: 2.3924 Acc: 0.6773\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 2.0821 Acc: 0.6277\n",
      "val Loss: 1.5538 Acc: 0.7896\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.5304 Acc: 0.7383\n",
      "val Loss: 1.1476 Acc: 0.8316\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.1682 Acc: 0.7984\n",
      "val Loss: 0.8978 Acc: 0.8539\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.9313 Acc: 0.8291\n",
      "val Loss: 0.7340 Acc: 0.8697\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.7776 Acc: 0.8514\n",
      "val Loss: 0.6264 Acc: 0.8752\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8652\n",
      "val Loss: 0.5503 Acc: 0.8806\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.5753 Acc: 0.8842\n",
      "val Loss: 0.5054 Acc: 0.8828\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.5157 Acc: 0.8872\n",
      "val Loss: 0.4663 Acc: 0.8863\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.4680 Acc: 0.8973\n",
      "val Loss: 0.4447 Acc: 0.8809\n",
      "Training complete in 6m 49s\n",
      "Best val Acc: 0.886345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=1e-3, \n",
    "                       #weight_decay=1e-5,\n",
    "                       #betas=(0.9, 0.999),\n",
    "                      )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr=1e-2,\n",
    "                                                steps_per_epoch=len(dataloaders['train']), epochs=epochs)\n",
    "\n",
    "\n",
    "model, val_acc_history, loss_history, acc_history = train_model(model = model,\n",
    "                                          num_epochs = epochs,\n",
    "                                          dataloaders = dataloaders,\n",
    "                                          criterion = criterion,\n",
    "                                          optimizer = optimizer,\n",
    "                                          scheduler = None#scheduler\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ba0a760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11612\\2455295320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mplot2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#score(model, test_dataloader, criterion)\n",
    "\n",
    "yvals = list(range(1,epochs+1))\n",
    "newloss = []\n",
    "newacc = []\n",
    "for i in range(len(loss_history)):\n",
    "    if i % 2 == 0:\n",
    "        newloss.append(loss_history[i])\n",
    "        newacc.append(acc_history[i])\n",
    "\n",
    "plot1 = plt.figure(figsize=(10,5))\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(yvals,newloss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "print(yvals)\n",
    "print(acc_history[0].cpu().items())\n",
    "plot2 = plt.figure(figsize=(10,5))\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(yvals,newacc)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac82461",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "    layer_names.append(name)\n",
    "\n",
    "layer_names.reverse()\n",
    "\n",
    "# learning rate\n",
    "lr      = 1e-4\n",
    "lr_mult = 0.9\n",
    "\n",
    "# placeholder\n",
    "parameters = []\n",
    "\n",
    "# store params & learning rates\n",
    "for idx, name in enumerate(layer_names):\n",
    "    \n",
    "    # display info\n",
    "    print(f'{idx}: lr = {lr:.6f}, {name}')\n",
    "    \n",
    "    # append layer parameters\n",
    "    parameters += [{'params': [p for n, p in model.named_parameters() if n == name and p.requires_grad],\n",
    "                    'lr':     lr}]\n",
    "    \n",
    "    # update learning rate\n",
    "    lr *= lr_mult\n",
    "\n",
    "optimizer = optim.Adam(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_parameter_requires_grad(model, False)\n",
    "\n",
    "    \n",
    "\"\"\"optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=1e-6, \n",
    "                       weight_decay=1e-5,\n",
    "                       betas=(0.9, 0.999),\n",
    "                      )\"\"\"\n",
    "\n",
    "finetune_epochs = 7\n",
    "\"\"\"scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr=1e-4,\n",
    "                                                steps_per_epoch=len(dataloaders['train']),\n",
    "                                                epochs=finetune_epochs)\"\"\"\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, 0.5)\n",
    "\n",
    "best_model, val_acc_history, loss_history, acc_history = train_model(model = model,\n",
    "                                          num_epochs = finetune_epochs,\n",
    "                                          dataloaders = dataloaders,\n",
    "                                          criterion = criterion,\n",
    "                                          optimizer = optimizer,\n",
    "                                          scheduler = scheduler\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6673d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(best_model, test_dataloader, criterion)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd82e6248dbff03038d799f8cb0a4b7e2d88f22b02718fef3b6ea553d7792884"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
