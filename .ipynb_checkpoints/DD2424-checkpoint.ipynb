{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe319f9-b63a-4c8b-998a-2e199665bd14",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916c7fe-58b4-40c7-a3d4-352488ece0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time\n",
    "import copy\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94751a-8852-409e-b9f4-8f18fb62f461",
   "metadata": {},
   "source": [
    "## Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55608c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_classes = 37 #Number of classes in dataset\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 224\n",
    "batch_size = 128\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2ab8a-d589-49f3-a70a-e1a39e687973",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0571b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    params_to_update = list(model.named_parameters())\n",
    "    \n",
    "    if feature_extracting:\n",
    "        for name, param in params_to_update:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    else:\n",
    "        for name, param in params_to_update[:-15]:\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extracting): #Initialize Resnet\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True) \n",
    "        \n",
    "        set_parameter_requires_grad(model, feature_extracting)\n",
    "        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,num_classes) # Update last layer to binary classification (Dog/cat)\n",
    "        input_size = 224 #\"Finally, notice that inception_v3 requires the input size to be (299,299), whereas all of the other models expect (224,224).\"\n",
    "        model = model.to(device)\n",
    "        \n",
    "    return model, input_size\n",
    "\n",
    "\n",
    "\n",
    "def readData(target_type = 'breeds'):\n",
    "    breed_to_species = {0:0, 1:1, 2:1, 3:1, 4:1, 5:0, 6:0, 7:0, 8:1, 9:0, 10:1,\n",
    "                    11:0, 12:1, 13:1, 14:1, 15:1, 16:1, 17:1, 18:1, 19:1, 20:0,\n",
    "                    21:1, 22:1, 23:0, 24:1, 25:1, 26:0, 27:0, 28:1, 29:1, 30:1,\n",
    "                    31:1, 32:0, 33:0, 34:1, 35:1, 36:1\n",
    "                   }\n",
    "    \n",
    "    transform = T.Compose([T.Resize(image_size),\n",
    "                           T.CenterCrop(image_size),\n",
    "                           T.ToTensor(),\n",
    "                           #T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                           #T.RandomHorizontalFlip(),\n",
    "                           #T.RandomRotation(degrees=15),\n",
    "                           #T.RandomResizedCrop(size=224)\n",
    "                          ])\n",
    "    \n",
    "    if target_type == 'species':\n",
    "        target_function = (lambda x: breed_to_species.get(x))\n",
    "    elif target_type == 'breeds':\n",
    "        target_function = None\n",
    "    else:\n",
    "        raise Exception(\"Wrong target type\")\n",
    "        \n",
    "    trainval = OxfordIIITPet(path,\n",
    "                             target_types= \"category\",\n",
    "                             transform=transform,\n",
    "                             split = 'trainval',\n",
    "                             target_transform = target_function,\n",
    "                             download = True\n",
    "                            )\n",
    "    test = OxfordIIITPet(path,\n",
    "                         target_types= \"category\",\n",
    "                         transform=transform,\n",
    "                         split = 'test',\n",
    "                         target_transform = target_function\n",
    "                        )\n",
    "                         \n",
    "    train, val = splitData(trainval, 0.8, 0.2)\n",
    "    return train, val, test\n",
    "    \n",
    "def splitData(dataset,nrTrain,nrVal):\n",
    "    len1 = int(nrTrain*len(dataset))\n",
    "    len2 = int(len(dataset) - len1)\n",
    "    train, val = torch.utils.data.random_split(dataset, [len1,len2])\n",
    "    return train, val\n",
    "\n",
    "def show_example(img, label):\n",
    "    print('Label: ', train_dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa2c0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c280de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, dataloader):\n",
    "    running_corrects = 0\n",
    "    model.eval()\n",
    "    for inputs, labels in dataloader:\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    print('Acc: {:4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b1231-ee47-46e8-aff6-2e3183576585",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "959f4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = readData(\n",
    "                            #target_type = 'species'\n",
    "                            target_type = 'breeds'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad5db5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/da150x_47/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model,input_size = initialize_model(model_name = \"resnet\",\n",
    "                                    num_classes = 37,\n",
    "                                    feature_extracting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b1efce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.7852 Acc: 0.5058\n",
      "val Loss: 2.5591 Acc: 0.3424\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.0911 Acc: 0.6719\n",
      "val Loss: 1.7421 Acc: 0.5149\n",
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     15\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m lr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m best_model, val_acc_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# backward + optimize only if in training phase\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloaders = {label: torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=4)\n",
    "          for label, data in zip(['train', 'val'],[train, val])}\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.001,\n",
    "                       #weight_decay = 0.01\n",
    "                      )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "best_model, val_acc_history = train_model(model = model,\n",
    "                                          num_epochs = 20,\n",
    "                                          dataloaders = dataloaders,\n",
    "                                          criterion = criterion,\n",
    "                                          optimizer = optimizer,\n",
    "                                          scheduler = scheduler\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, val_acc_history = train_model(model = best_model,\n",
    "                                          num_epochs = 4,\n",
    "                                          dataloaders = dataloaders,\n",
    "                                          criterion = criterion,\n",
    "                                          optimizer = optimizer,\n",
    "                                          scheduler = scheduler\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274afc16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
